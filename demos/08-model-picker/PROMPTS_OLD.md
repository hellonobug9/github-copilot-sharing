# Model Selection ‚Äì Ch·ªçn AI Model Ph√π H·ª£p

## TL;DR

VS Code Copilot h·ªó tr·ª£ nhi·ªÅu AI models:
- **Claude 3.5 Sonnet** ‚Üí Code generation, refactor (fast, balanced)
- **GPT-4o** ‚Üí Creative tasks, documentation, explanations (fast)
- **o1-preview** ‚Üí Complex algorithms, architecture design (slow, smart)
- **o1-mini** ‚Üí Quick reasoning, debugging logic (medium speed)

**Rule of thumb:**

| Task | Model ph√π h·ª£p | L√Ω do |
|------|---------------|-------|
| Code th∆∞·ªùng ng√†y | Claude 3.5 Sonnet | Fast, good balance |
| Explain/docs | GPT-4o | Good at natural language |
| Complex algorithm | o1-preview | Deep reasoning |
| Quick debug | o1-mini | Fast reasoning, cheap |

> Task ƒë∆°n gi·∫£n ‚Üí Claude/GPT-4o. Task ph·ª©c t·∫°p c·∫ßn think deep ‚Üí o1-preview. C·∫ßn nhanh + r·∫ª ‚Üí o1-mini.

---

## 1. Available Models

### Overview

| Model | Provider | Speed | Cost | Best For |
|-------|----------|-------|------|----------|
| **Claude 3.5 Sonnet** | Anthropic | ‚ö° Fast | ‚≠ê‚≠ê Medium | Code gen, refactor |
| **GPT-4o** | OpenAI | ‚ö° Fast | ‚≠ê‚≠ê Medium | Docs, explanations |
| **o1-preview** | OpenAI | üê¢ Slow | ‚≠ê‚≠ê‚≠ê High | Algorithms, design |
| **o1-mini** | OpenAI | ‚ö°‚ö° Medium | ‚≠ê Low | Quick reasoning |

---

### C√°ch switch models

1. M·ªü Chat View
2. Click v√†o model dropdown (g√≥c tr√™n b√™n tr√°i)
3. Ch·ªçn model

Ho·∫∑c:
- Settings ‚Üí "github.copilot.model"

---

## 2. Claude 3.5 Sonnet

### ƒêi·ªÉm m·∫°nh

- ‚úÖ **Code generation r·∫•t t·ªët**
- ‚úÖ Hi·ªÉu context codebase t·ªët
- ‚úÖ Fast response time
- ‚úÖ Balanced gi·ªØa speed v√† quality
- ‚úÖ T·ªët v·ªõi TypeScript, React, Node.js

### ƒêi·ªÉm y·∫øu

- ‚ö†Ô∏è Kh√¥ng ƒë·∫∑c bi·ªát v·ªõi complex algorithms
- ‚ö†Ô∏è Deep reasoning k√©m h∆°n o1-preview

### D√πng cho

**1. Code generation h·∫±ng ng√†y**
```
Generate a React component for user profile card with avatar, name, bio
```

**2. Refactoring**
```
Refactor this function to use async/await and add proper error handling
```

**3. Convert code**
```
Convert this JavaScript code to TypeScript with proper types
```

**4. Add features**
```
Add pagination support to this API endpoint
```

### V√≠ d·ª• prompt

```
Create a custom React hook for debouncing user input
```

**Claude output:**
```typescript
import { useState, useEffect } from 'react';

export function useDebounce<T>(value: T, delay: number = 500): T {
  const [debouncedValue, setDebouncedValue] = useState<T>(value);

  useEffect(() => {
    const handler = setTimeout(() => {
      setDebouncedValue(value);
    }, delay);

    return () => {
      clearTimeout(handler);
    };
  }, [value, delay]);

  return debouncedValue;
}
```

‚úÖ Clean, practical code

---

## 3. GPT-4o

### ƒêi·ªÉm m·∫°nh

- ‚úÖ **Natural language tasks** r·∫•t t·ªët
- ‚úÖ Explanations chi ti·∫øt
- ‚úÖ Documentation quality cao
- ‚úÖ Creative v·ªõi naming, comments
- ‚úÖ Fast response

### ƒêi·ªÉm y·∫øu

- ‚ö†Ô∏è Code generation k√©m h∆°n Claude m·ªôt ch√∫t
- ‚ö†Ô∏è C√≥ th·ªÉ verbose (d√†i d√≤ng)

### D√πng cho

**1. Explain code/concepts**
```
Explain how React useEffect works with dependencies
```

**2. Write documentation**
```
Write comprehensive README for this project
```

**3. Generate examples**
```
Show me 5 examples of using Promise.all in real scenarios
```

**4. Brainstorm**
```
Suggest 10 feature ideas for a task management app
```

### V√≠ d·ª• prompt

```
Explain the difference between useMemo and useCallback with examples
```

**GPT-4o output:**
```markdown
## useMemo vs useCallback

Both are React hooks for optimization, but they memoize different things:

### useMemo - Memoizes **values**

Caches the **result** of a computation.

**Use case:** Expensive calculations

**Example:**
```typescript
const expensiveValue = useMemo(() => {
  return items.reduce((sum, item) => sum + item.price, 0);
}, [items]);
```

Without useMemo: Calculation runs on every render
With useMemo: Calculation only runs when `items` changes

### useCallback - Memoizes **functions**

Caches the **function instance** itself.

**Use case:** Passing callbacks to optimized child components

**Example:**
```typescript
const handleClick = useCallback(() => {
  console.log('Clicked', userId);
}, [userId]);

return <ChildComponent onClick={handleClick} />;
```

Without useCallback: New function instance on every render ‚Üí child re-renders
With useCallback: Same function instance if `userId` unchanged ‚Üí no re-render

### Rule of thumb:

- **useMemo**: "This calculation is expensive"
- **useCallback**: "This function is passed to optimized children"
```

‚úÖ Clear explanations, good examples

---

## 4. o1-preview

### ƒêi·ªÉm m·∫°nh

- ‚úÖ **Deep reasoning** - "thinks" before answering
- ‚úÖ T·ªët v·ªõi complex algorithms
- ‚úÖ System design, architecture
- ‚úÖ Gi·∫£i quy·∫øt b√†i to√°n logic ph·ª©c t·∫°p
- ‚úÖ Trade-off analysis

### ƒêi·ªÉm y·∫øu

- ‚ö†Ô∏è **R·∫•t ch·∫≠m** (30s - 2 ph√∫t)
- ‚ö†Ô∏è **T·ªën token nhi·ªÅu**
- ‚ö†Ô∏è Free tier c√≥ **gi·ªõi h·∫°n requests/day**
- ‚ö†Ô∏è Overkill cho tasks ƒë∆°n gi·∫£n

### D√πng cho

**1. Algorithm design**
```
Design an efficient algorithm to find the k-th largest element in a stream of integers
```

**2. Architecture decisions**
```
Design a scalable caching strategy for an e-commerce site that handles:
- Cache invalidation across multiple servers
- Rate limiting per user
- Concurrent requests to same resource
- Memory constraints

Analyze trade-offs of different approaches.
```

**3. Complex debugging**
```
This distributed system has a race condition. Analyze the code and suggest solutions:
[paste complex multi-threaded code]
```

**4. Optimization**
```
Optimize this database query for a table with 100M rows:
[paste query]

Consider indexes, query planning, and alternative approaches.
```

### V√≠ d·ª• prompt

```
Design a rate limiting system that:
- Supports multiple rate limit rules (per user, per IP, per API key)
- Scales to millions of requests per second
- Has minimal latency overhead
- Is distributed across multiple servers

Analyze trade-offs of different approaches.
```

**o1-preview output:**
```markdown
Let me analyze different approaches for distributed rate limiting:

## Approach 1: Token Bucket with Redis

**Architecture:**
- Central Redis cluster stores token counts
- Each API server checks Redis before allowing requests
- Atomic operations ensure consistency

**Pros:**
- Simple to implement
- Consistent across all servers
- Easy to monitor

**Cons:**
- Redis becomes bottleneck at extreme scale
- Network latency to Redis on every request (~1-2ms)
- Single point of failure (mitigated with Redis Cluster)

**Good for:** Up to ~100K RPS

## Approach 2: Leaky Bucket with Local Cache + Eventual Consistency

**Architecture:**
- Each server maintains local token bucket
- Sync state to Redis periodically (every 100ms)
- Accept small inconsistencies

**Pros:**
- Very low latency (local check only)
- Scales to millions of RPS
- Redis only for sync, not on critical path

**Cons:**
- Slightly inaccurate (user might exceed limit by ~10% during sync window)
- More complex implementation
- Requires careful tuning

**Good for:** >100K RPS, can tolerate small errors

## Approach 3: Distributed Counter with Consistent Hashing

**Architecture:**
- Partition key space across servers using consistent hashing
- Each request routes to deterministic server based on user ID
- No central Redis for hot path

**Pros:**
- Horizontally scalable
- No single point of failure
- Sub-millisecond latency

**Cons:**
- Complex to implement
- Rebalancing on server add/remove
- Requires cluster management

**Good for:** Extreme scale (>1M RPS), mission-critical

## Recommendation:

For most cases: **Approach 2** (Local + Eventual Consistency)

Reasoning:
- Balances performance, scalability, complexity
- 10% error margin acceptable for rate limiting
- Easy to tune sync frequency vs accuracy
- Redis only for coordination, not bottleneck

Implementation sketch:
[detailed pseudocode follows...]
```

‚úÖ Deep analysis, considers trade-offs, practical recommendation

---

## 5. o1-mini

### ƒêi·ªÉm m·∫°nh

- ‚úÖ **Fast reasoning** - c√≥ kh·∫£ nƒÉng reason nh∆∞ng nhanh h∆°n o1-preview
- ‚úÖ **R·∫ª token** nh·∫•t trong c√°c reasoning models
- ‚úÖ T·ªët cho debugging, logic issues
- ‚úÖ Good balance gi·ªØa speed v√† reasoning

### ƒêi·ªÉm y·∫øu

- ‚ö†Ô∏è Reasoning kh√¥ng s√¢u b·∫±ng o1-preview
- ‚ö†Ô∏è Less creative

### D√πng cho

**1. Quick debugging**
```
Why is this loop not terminating?
[paste code]
```

**2. Logic issues**
```
Find the bug in this conditional logic:
[paste code]
```

**3. Code review**
```
Review this function for potential issues
```

**4. Quick algorithm questions**
```
What's the time complexity of this code?
```

### V√≠ d·ª• prompt

```
Why does this infinite loop happen?

```typescript
let i = 0;
while (i < 10) {
  console.log(i);
  i += 0.1;
  if (i === 5) break;
}
```
```

**o1-mini output:**
```
The loop is infinite because of **floating-point precision issues**.

**Problem:**
`i` is incremented by 0.1, but 0.1 cannot be represented exactly in binary floating-point.

After multiple additions:
- i = 4.9 (ok)
- i = 5.0? No, it's actually 4.999999999999999 or 5.000000000000001
- i === 5 never true due to precision error
- Loop continues forever

**Fix 1: Use epsilon comparison**
```typescript
if (Math.abs(i - 5) < 0.0001) break;
```

**Fix 2: Use integer counter**
```typescript
for (let i = 0; i < 100; i++) {
  const value = i * 0.1;
  console.log(value);
  if (i === 50) break;
}
```

**Fix 3: Avoid floating-point in loop condition**
```typescript
for (let i = 0; i < 50; i++) {
  const value = i / 10;
  console.log(value);
}
```

Recommended: Fix 2 or 3
```

‚úÖ Quick, correct diagnosis + practical fixes

---

## 6. Khi n√†o d√πng model n√†o?

### Decision Tree

```
Task c·ªßa b·∫°n l√† g√¨?

‚îú‚îÄ Code generation th∆∞·ªùng ng√†y (components, functions, refactor)
‚îÇ  ‚îî‚îÄ ‚úÖ Claude 3.5 Sonnet (default choice)
‚îÇ
‚îú‚îÄ Explain concepts, write docs, brainstorm
‚îÇ  ‚îî‚îÄ ‚úÖ GPT-4o
‚îÇ
‚îú‚îÄ Complex algorithm, architecture design, trade-off analysis
‚îÇ  ‚îî‚îÄ ‚úÖ o1-preview (accept slow speed)
‚îÇ
‚îî‚îÄ Quick debugging, logic issues, code review
   ‚îî‚îÄ ‚úÖ o1-mini
```

---

### V√≠ d·ª• th·ª±c t·∫ø

| Task | Model | L√Ω do |
|------|-------|-------|
| "Create a login form component" | Claude 3.5 | Standard code gen |
| "Explain React context" | GPT-4o | Explanation task |
| "Design a distributed cache" | o1-preview | Complex system design |
| "Why is this function returning undefined?" | o1-mini | Quick debug |
| "Refactor this messy code" | Claude 3.5 | Code refactor |
| "Write README for this project" | GPT-4o | Documentation |
| "Optimize this sorting algorithm" | o1-preview | Algorithm optimization |
| "Find the bug in this if-statement" | o1-mini | Simple logic bug |

---

## 7. Token Cost v√† Free Tier Limits

### Free Tier (Copilot Free)

- **Limited completions per month**
- **Limited chat interactions per month**
- **o1-preview/o1-mini c√≥ gi·ªõi h·∫°n th·∫•p h∆°n**

### Paid Tiers

- **Copilot Individual**: Higher limits
- **Copilot Business**: Even higher limits
- **o1-models v·∫´n ƒë·∫Øt h∆°n** Claude/GPT-4o

### Best practice ƒë·ªÉ ti·∫øt ki·ªám token

**1. D√πng model ph√π h·ª£p**
- ƒê·ª´ng d√πng o1-preview cho tasks ƒë∆°n gi·∫£n
- Default: Claude 3.5 Sonnet

**2. Vi·∫øt prompts ng·∫Øn g·ªçn**
- C·ª• th·ªÉ, kh√¥ng d√†i d√≤ng
- Avoid redundancy

**3. D√πng inline suggestions khi c√≥ th·ªÉ**
- Kh√¥ng t·ªën chat tokens
- Nhanh h∆°n

**4. Review output tr∆∞·ªõc khi regenerate**
- ƒê·ª´ng spam regenerate
- Clarify prompt thay v√¨ re-ask

---

## 8. Best Practices

### 1Ô∏è‚É£ Start v·ªõi Claude 3.5 Sonnet (default)

80% tasks ‚Üí Claude l√† ƒë·ªß

Switch models ch·ªâ khi:
- C·∫ßn explanation chi ti·∫øt ‚Üí GPT-4o
- Task r·∫•t ph·ª©c t·∫°p ‚Üí o1-preview
- Debug nhanh ‚Üí o1-mini

---

### 2Ô∏è‚É£ Switch model gi·ªØa conversation

C√≥ th·ªÉ switch model gi·ªØa chat:
```
Step 1 (Claude): Generate this function
[review output]

Step 2 (o1-preview): Analyze performance bottlenecks
[detailed analysis]

Step 3 (Claude): Implement optimization
```

---

### 3Ô∏è‚É£ Evaluate output quality

N·∫øu Claude cho k·∫øt qu·∫£ kh√¥ng t·ªët:
1. Improve prompt (often the issue)
2. Try GPT-4o
3. Last resort: o1-preview

ƒê·ª´ng assume "model kh√°c = t·ªët h∆°n"

---

### 4Ô∏è‚É£ Check free tier limits

N·∫øu hit limits:
- Wait for reset (monthly)
- Upgrade to paid tier
- Use inline suggestions more

---

## 9. Demo Scenarios

### Demo 1: So s√°nh models cho c√πng 1 task

**Task:** "Explain closures in JavaScript"

**Claude 3.5 Sonnet:**
```
Closures are functions that remember variables from their outer scope...
[concise, practical explanation]
```

**GPT-4o:**
```
# Understanding Closures in JavaScript

A closure is a powerful concept...
[detailed, structured explanation with multiple examples]
```

**o1-preview:**
```
Let me break down closures systematically...
[deep dive into lexical scope, execution contexts, use cases, gotchas]
```

‚Üí GPT-4o best cho explanation tasks

---

### Demo 2: Complex task c·∫ßn o1-preview

**Task:**
```
Design a consensus algorithm for a distributed key-value store that tolerates Byzantine failures
```

**Claude/GPT-4o:**
‚Üí Generic answer, kh√¥ng s√¢u

**o1-preview:**
‚Üí Detailed analysis of Raft vs Paxos vs PBFT, trade-offs, implementation considerations

---

### Demo 3: Quick debug v·ªõi o1-mini

**Task:**
```
Why is this array empty?

const results = [];
[1,2,3].forEach(n => {
  setTimeout(() => results.push(n), 0);
});
console.log(results); // []
```

**o1-mini:**
```
The array is empty because `console.log` executes immediately,
but `setTimeout` callbacks execute later (asynchronously).

By the time callbacks run, console.log has already printed.

Fix with Promise.all:
[code example]
```

‚úÖ Fast, correct answer

---

## T√≥m l·∫°i

### Model Comparison

| Model | Speed | Cost | Best For |
|-------|-------|------|----------|
| **Claude 3.5** | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | Code gen (default) |
| **GPT-4o** | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | Explanations, docs |
| **o1-preview** | üê¢ | ‚≠ê‚≠ê‚≠ê | Complex algorithms, design |
| **o1-mini** | ‚ö°‚ö° | ‚≠ê | Quick debugging, reasoning |

### Quick Reference

| Task Type | Use Model | Why |
|-----------|-----------|-----|
| Daily coding | Claude 3.5 | Fast, balanced |
| Explain/Docs | GPT-4o | Best at natural language |
| System design | o1-preview | Deep reasoning |
| Quick debug | o1-mini | Fast + cheap |

**C√¢u nh·ªõ:**
> 80% tasks d√πng Claude. Explain ‚Üí GPT-4o. Complex ‚Üí o1-preview. Debug nhanh ‚Üí o1-mini.
